root: "www.example.com"
locator_strings:
- '[class*="headline"]'
robots_txt_url: "www.example.com/robots.txt"
ignore_robots_txt: false
max_pages: 20
max_workers: 20
save_path: "scraped_items.json"
save_checkpoint: false
headless: true
user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
